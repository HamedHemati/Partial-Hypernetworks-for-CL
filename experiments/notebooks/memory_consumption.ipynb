{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###################################################\n",
    "# Change current directory to the root of the project\n",
    "import os\n",
    "from pathlib import Path\n",
    "current_dir = Path(os.getcwd())\n",
    "os.chdir(current_dir.parents[1])\n",
    "# ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from omegaconf.omegaconf import OmegaConf\n",
    "from hyper_cl.models import get_model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18LatentReplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 160, 4, 4])\n",
      "Memory consumption: 1.95 MB\n",
      "Parameter shape: torch.Size([200, 160, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "config = {\"n_classes\": 100,\n",
    "          \"model\": \"ResNet18LatentReplay\",\n",
    "          \"multi_head\": True,\n",
    "          \"latent_depth\": 5,\n",
    "          \"seed\": 0\n",
    "          }\n",
    "\n",
    "config = OmegaConf.create(config)\n",
    "\n",
    "model = get_model(config)\n",
    "\n",
    "x = torch.randn(200, 3, 32, 32)\n",
    "feats = model.extract_feat(x)\n",
    "print(feats.shape)\n",
    "mem_consumption = feats.numel() * feats.element_size()\n",
    "mem_consumption_MB = mem_consumption / (1024 * 1024)\n",
    "\n",
    "# Memory consumption\n",
    "print(f\"Memory consumption: {mem_consumption_MB:.2f} MB\")\n",
    "# Parameter shape\n",
    "print(f\"Parameter shape: {feats.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Resnet-SH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory consumption: 4.86 MB\n",
      "Number of HN parameters: 1272877\n"
     ]
    }
   ],
   "source": [
    "config = {\"n_classes\": 100,\n",
    "          \"model\": \"HyperResNet18SH\",\n",
    "          # \"model\": \"HyperResNet18SPv1SH\",\n",
    "          # \"model\": \"HyperResNet18SPv2SH\",\n",
    "          # \"model\": \"HyperResNet18SPv3SH\",\n",
    "          # \"model\": \"HyperResNet18SPv4SH\",\n",
    "          \"model_params\": {\n",
    "              \"embd_dim\": 32,\n",
    "              \"hidden_size_1\": 50,\n",
    "              \"hidden_size_2\": 32,\n",
    "              \"head_emb_dim\": 32\n",
    "          },\n",
    "          \"bnch_params\": {\n",
    "            \"n_experiences\": 20,\n",
    "            \"return_task_id\": True,\n",
    "            },\n",
    "          \"seed\": 0\n",
    "          }\n",
    "\n",
    "config = OmegaConf.create(config)\n",
    "\n",
    "model = get_model(config)\n",
    "\n",
    "mem_consumption_MB = (model.weight_generator.n_params * 4) / (1024 * 1024)\n",
    "print(f\"Memory consumption: {mem_consumption_MB:.2f} MB\")\n",
    "print(f\"Number of HN parameters: {model.weight_generator.n_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
